{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1679675836580,"user":{"displayName":"vishnu vardhan","userId":"07969204109325658924"},"user_tz":-330},"id":"wpbQmPTG9vtH","outputId":"16d68d81-67e9-472a-87d9-43d3deb872a6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n","/usr/local/lib/python3.9/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  deprecation(\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as f\n","import torch.optim as optim\n","import numpy as np\n","import random\n","import gym\n","env = gym.make(\"CartPole-v1\")\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j63_7sHAp-X6"},"outputs":[],"source":["class Buffer:\n","  def __init__(self,buffer_size,batch_size):\n","    self.buffer_size = buffer_size\n","    self.batch_size = batch_size\n","    self.states      = []\n","    self.next_states = []\n","    self.rewards     = []\n","    self.terminals   = []\n","    self.actions     = []\n","    self.cntr        = 0\n","    self.clear()\n","  def store(self,state,next_state,reward,terminal,action):\n","    self.states.append(state)\n","    self.next_states.append(next_state)\n","    self.rewards.append(reward)\n","    self.terminals.append(terminal)\n","    self.actions.append(action)\n","    self.cntr +=1\n","  def sample(self):\n","    index  = random.sample(range(len(self.states)),self.batch_size)\n","    states = np.array(self.states)[index] \n","    next_states = np.array(self.next_states)[index]\n","    rewards     = np.array(self.rewards)[index]\n","    terminals   = np.array(self.terminals)[index]\n","    return states ,next_states,rewards,terminals\n","  def clear(self):\n","    if self.cntr == self.buffer_size:\n","      self.states      = []\n","      self.next_states = []\n","      self.rewards     = []\n","      self.terminals   = []\n","      self.actions     = []\n","      self.cntr        = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RyfYCaAi2sK3"},"outputs":[],"source":["class Network(nn.Module):\n","  def __init__(self,state_size,action_size):\n","    super(Network,self).__init__()\n","    self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    self.state_size = state_size\n","    self.action_size = action_size\n","    self.lin1 = nn.Linear(4,64)\n","    self.lin2 = nn.Linear(64,128)\n","    self.lin3 = nn.Linear(128,64)\n","    self.lin4 = nn.Linear(64,self.action_size)\n","    self.to(self.device)\n","  def forward(self,x):\n","    x = f.relu(self.lin1(x))\n","    x = f.relu(self.lin2(x))\n","    x = f.relu(self.lin3(x))\n","    x = self.lin4(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"phQE-DHn4fvC"},"outputs":[],"source":["class Agent:\n","  def __init__(self,state_size,action_size,buffer_size,batch_size,episodes,steps):\n","    self.state_size  = state_size\n","    self.action_size = action_size \n","    self.buffer_size = buffer_size\n","    self.batch_size  = batch_size\n","    self.episodes    = episodes\n","    self.steps       = steps\n","    self.epislon     = 1\n","    self.gamma       = 0.99\n","    self.epislon_end = 0.01\n","    self.epislon_dec = 100000\n","    self.lr          = 0.00005\n","    self.episode     = []\n","    self.loss        = []\n","    self.device      = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    self.buffer      = Buffer(self.buffer_size,self.batch_size) \n","    self.q_net       = Network(self.state_size,self.action_size)\n","    self.tar_net     = Network(self.state_size,self.action_size)\n","    self.optim       = optim.Adam(self.q_net.parameters() ,lr = self.lr)\n","    self.tar_net.load_state_dict(self.q_net.state_dict())\n","    self.mean_loss   = []\n","    self.mean_epi    = []\n","    self.mean_reward = []\n","    self.rewards     = []\n","  def save(self):\n","    torch.save(self.q_net.state_dict(),\"DQNq_net.pth\")\n","  def load(self):\n","    self.q_net.load_state_dict(torch.load(\"DQNq_net.pth\"))\n","  def choose_actions(self,state):\n","    state = torch.tensor(state,dtype = torch.float32).to(self.device)\n","    if random.random() <= self.epislon:\n","      action =  env.action_space.sample()\n","      action =  torch.tensor(action)\n","    else:\n","      q_values = self.q_net(state)\n","      action   = q_values[torch.argmax(q_values).item()]\n","    return action.item()\n","  def learn(self):\n","    if len(self.buffer.states) < self.batch_size:\n","      self.loss.append(0)\n","      return \n","    else:\n","      states , next_states, rewards , terminals = self.buffer.sample()\n","      states = torch.tensor(states,dtype = torch.float32).to(self.device)\n","      next_states = torch.tensor(next_states,dtype = torch.float32).to(self.device)\n","      rewards = torch.tensor(rewards,dtype = torch.float32).to(self.device)\n","      q_value = self.q_net(states)\n","      q_tar   = self.tar_net(next_states)\n","      y       = sum(rewards) + self.gamma * q_value\n","      loss    = torch.tensor((y-q_value)**2,requires_grad = True)\n","      loss    = loss.mean()\n","      self.loss.append(loss.detach().numpy())\n","      self.save()\n","      self.load()\n","      self.optim.zero_grad()\n","      loss.backward()\n","      self.optim.step()\n","  def ploting(self):\n","    plt.plot(self.mean_epi,self.mean_loss)\n","    plt.xlabel(\"count\")\n","    plt.ylabel(\"loss\")\n","    plt.savefig(\"DQN\\cartpole.png\")\n","    plt.close()\n","\n","  def train(self):\n","    count = 0\n","    for i in range(self.episodes):\n","      state = env.reset()\n","      for j in range(self.steps):\n","        action = self.choose_actions(state)\n","        next_state,reward,done,info = env.step(action)\n","        self.buffer.store(state,next_state,reward,done,action)\n","        self.episode.append(count)\n","        self.rewards.append(reward)\n","        if done:\n","          self.learn()\n","          state = next_state\n","        else:\n","          self.learn()\n","          state = next_state\n","          self.ploting()\n","        count +=1\n","      self.mean_loss.append(sum(self.loss)/len(self.loss))\n","      self.mean_epi.append(i)\n","      self.mean_reward.append(sum(self.rewards)/len(self.rewards))\n","      print(f'episode : {i} / {self.episodes} ; reward : {self.mean_reward[-1]} ; loss : {self.mean_loss[-1]}')\n","      self.loss,self.rewards = [],[]\n","  def test(self):\n","    pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gf6943d2_laj"},"outputs":[],"source":["Agent = Agent(env.observation_space.shape[0],env.action_space.n,10000,32,10000,350)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"_OLDf7yMGG-7","outputId":"c984b6a8-0d0a-47ac-e27f-81953f77639d"},"outputs":[{"name":"stderr","output_type":"stream","text":["<ipython-input-81-c64ef2e6c74c>:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  loss    = torch.tensor((y-q_value)**2,requires_grad = True)\n"]},{"name":"stdout","output_type":"stream","text":["episode : 0 / 10000 ; reward : 0.03428571428571429 ; loss : 13.204269672330959\n","episode : 1 / 10000 ; reward : 0.08571428571428572 ; loss : 5.8883430613086745\n","episode : 2 / 10000 ; reward : 0.12285714285714286 ; loss : 12.312359430183344\n","episode : 3 / 10000 ; reward : 0.05142857142857143 ; loss : 9.960888735083396\n","episode : 4 / 10000 ; reward : 0.13428571428571429 ; loss : 11.202578119274614\n","episode : 5 / 10000 ; reward : 0.054285714285714284 ; loss : 11.960983573008228\n","episode : 6 / 10000 ; reward : 0.04857142857142857 ; loss : 8.92586018075373\n","episode : 7 / 10000 ; reward : 0.05714285714285714 ; loss : 8.945452559394576\n","episode : 8 / 10000 ; reward : 0.06285714285714286 ; loss : 8.070580499122794\n","episode : 9 / 10000 ; reward : 0.04285714285714286 ; loss : 8.085532299329726\n","episode : 10 / 10000 ; reward : 0.04857142857142857 ; loss : 7.227414149545371\n","episode : 11 / 10000 ; reward : 0.08857142857142856 ; loss : 7.767562110056922\n","episode : 12 / 10000 ; reward : 0.025714285714285714 ; loss : 7.301609387178245\n","episode : 13 / 10000 ; reward : 0.04285714285714286 ; loss : 6.518531389671484\n","episode : 14 / 10000 ; reward : 0.09142857142857143 ; loss : 6.213286223491341\n","episode : 15 / 10000 ; reward : 0.08285714285714285 ; loss : 7.327920076004319\n","episode : 16 / 10000 ; reward : 0.054285714285714284 ; loss : 7.0903846834200355\n","episode : 17 / 10000 ; reward : 0.07428571428571429 ; loss : 6.607033679187553\n","episode : 18 / 10000 ; reward : 0.054285714285714284 ; loss : 7.035731734334035\n","episode : 19 / 10000 ; reward : 0.04857142857142857 ; loss : 6.549981636308193\n","episode : 20 / 10000 ; reward : 0.03428571428571429 ; loss : 6.255248498769592\n","episode : 21 / 10000 ; reward : 0.04857142857142857 ; loss : 6.892784961496097\n","episode : 22 / 10000 ; reward : 0.045714285714285714 ; loss : 6.021231060410052\n","episode : 23 / 10000 ; reward : 0.08285714285714285 ; loss : 6.267422901117187\n","episode : 24 / 10000 ; reward : 0.07428571428571429 ; loss : 5.1094723972377665\n","episode : 25 / 10000 ; reward : 0.037142857142857144 ; loss : 6.876292773210653\n","episode : 26 / 10000 ; reward : 0.025714285714285714 ; loss : 6.1216164187146465\n","episode : 27 / 10000 ; reward : 0.07428571428571429 ; loss : 5.487095615924031\n","episode : 28 / 10000 ; reward : 0.04 ; loss : 5.129796756342574\n","episode : 29 / 10000 ; reward : 0.03428571428571429 ; loss : 5.832962287097242\n","episode : 30 / 10000 ; reward : 0.06857142857142857 ; loss : 6.075846546391872\n","episode : 31 / 10000 ; reward : 0.03142857142857143 ; loss : 4.975033162029499\n","episode : 32 / 10000 ; reward : 0.07714285714285714 ; loss : 6.201314670164077\n","episode : 33 / 10000 ; reward : 0.12 ; loss : 6.63569108960662\n","episode : 34 / 10000 ; reward : 0.03142857142857143 ; loss : 5.486618433430267\n","episode : 35 / 10000 ; reward : 0.04857142857142857 ; loss : 5.572546440174911\n","episode : 36 / 10000 ; reward : 0.07714285714285714 ; loss : 5.975743655422495\n","episode : 37 / 10000 ; reward : 0.07142857142857142 ; loss : 5.841364462733004\n","episode : 38 / 10000 ; reward : 0.04857142857142857 ; loss : 6.184465179698743\n","episode : 39 / 10000 ; reward : 0.037142857142857144 ; loss : 5.9959153546095525\n","episode : 40 / 10000 ; reward : 0.04857142857142857 ; loss : 5.246616726672607\n","episode : 41 / 10000 ; reward : 0.04285714285714286 ; loss : 5.232356236599587\n","episode : 42 / 10000 ; reward : 0.037142857142857144 ; loss : 5.5211141361276495\n","episode : 43 / 10000 ; reward : 0.14 ; loss : 5.735661744322038\n","episode : 44 / 10000 ; reward : 0.10285714285714286 ; loss : 6.129899824452905\n","episode : 45 / 10000 ; reward : 0.037142857142857144 ; loss : 6.2014872215818055\n","episode : 46 / 10000 ; reward : 0.08285714285714285 ; loss : 5.772282870911895\n","episode : 47 / 10000 ; reward : 0.1 ; loss : 6.435345553355114\n","episode : 48 / 10000 ; reward : 0.11142857142857143 ; loss : 6.295473763272381\n","episode : 49 / 10000 ; reward : 0.04 ; loss : 6.269833433843346\n","episode : 50 / 10000 ; reward : 0.12285714285714286 ; loss : 6.578704442313654\n","episode : 51 / 10000 ; reward : 0.04285714285714286 ; loss : 6.0213645659534345\n","episode : 52 / 10000 ; reward : 0.08 ; loss : 6.11840898203776\n","episode : 53 / 10000 ; reward : 0.06857142857142857 ; loss : 5.889595114097994\n","episode : 54 / 10000 ; reward : 0.06571428571428571 ; loss : 6.172807262882835\n","episode : 55 / 10000 ; reward : 0.05142857142857143 ; loss : 6.304361243533784\n","episode : 56 / 10000 ; reward : 0.04 ; loss : 5.804089883230279\n","episode : 57 / 10000 ; reward : 0.03142857142857143 ; loss : 6.17250038277089\n","episode : 58 / 10000 ; reward : 0.037142857142857144 ; loss : 6.290340441924714\n","episode : 59 / 10000 ; reward : 0.06285714285714286 ; loss : 6.530367236744852\n","episode : 60 / 10000 ; reward : 0.025714285714285714 ; loss : 6.210149614792227\n","episode : 61 / 10000 ; reward : 0.11428571428571428 ; loss : 5.772896658274878\n","episode : 62 / 10000 ; reward : 0.03428571428571429 ; loss : 6.1674503679556425\n","episode : 63 / 10000 ; reward : 0.04857142857142857 ; loss : 5.641199883502564\n","episode : 64 / 10000 ; reward : 0.04 ; loss : 5.578372655186959\n","episode : 65 / 10000 ; reward : 0.03142857142857143 ; loss : 5.789825888336312\n","episode : 66 / 10000 ; reward : 0.08571428571428572 ; loss : 5.266874021924454\n","episode : 67 / 10000 ; reward : 0.08 ; loss : 5.635621446544937\n","episode : 68 / 10000 ; reward : 0.025714285714285714 ; loss : 6.301926898621957\n","episode : 69 / 10000 ; reward : 0.13428571428571429 ; loss : 5.864430854702345\n","episode : 70 / 10000 ; reward : 0.13714285714285715 ; loss : 5.830136175522612\n","episode : 71 / 10000 ; reward : 0.07714285714285714 ; loss : 5.958682409489054\n","episode : 72 / 10000 ; reward : 0.09714285714285714 ; loss : 6.067375177476896\n","episode : 73 / 10000 ; reward : 0.045714285714285714 ; loss : 5.964402374333709\n","episode : 74 / 10000 ; reward : 0.03428571428571429 ; loss : 5.355574451257618\n","episode : 75 / 10000 ; reward : 0.06285714285714286 ; loss : 6.073100806751474\n","episode : 76 / 10000 ; reward : 0.04 ; loss : 6.347674254274793\n","episode : 77 / 10000 ; reward : 0.04857142857142857 ; loss : 5.9130625576009805\n","episode : 78 / 10000 ; reward : 0.04 ; loss : 6.155798360018036\n","episode : 79 / 10000 ; reward : 0.15428571428571428 ; loss : 5.995996467456919\n","episode : 80 / 10000 ; reward : 0.03428571428571429 ; loss : 5.990152591169275\n","episode : 81 / 10000 ; reward : 0.04857142857142857 ; loss : 5.510057257583856\n","episode : 82 / 10000 ; reward : 0.08857142857142856 ; loss : 6.061923376132711\n","episode : 83 / 10000 ; reward : 0.06285714285714286 ; loss : 6.824902191519052\n","episode : 84 / 10000 ; reward : 0.04 ; loss : 5.632854703513537\n","episode : 85 / 10000 ; reward : 0.06 ; loss : 5.464018918547667\n","episode : 86 / 10000 ; reward : 0.037142857142857144 ; loss : 5.7927361305239256\n","episode : 87 / 10000 ; reward : 0.03142857142857143 ; loss : 5.801355076935846\n","episode : 88 / 10000 ; reward : 0.07428571428571429 ; loss : 6.336022832105224\n","episode : 89 / 10000 ; reward : 0.10285714285714286 ; loss : 5.121232586284894\n","episode : 90 / 10000 ; reward : 0.06 ; loss : 5.7530867736236955\n","episode : 91 / 10000 ; reward : 0.16 ; loss : 6.576276495023711\n","episode : 92 / 10000 ; reward : 0.03428571428571429 ; loss : 6.6165006400268\n","episode : 93 / 10000 ; reward : 0.07142857142857142 ; loss : 6.107541435425058\n","episode : 94 / 10000 ; reward : 0.07428571428571429 ; loss : 6.599192452605491\n","episode : 95 / 10000 ; reward : 0.045714285714285714 ; loss : 6.099033833423354\n","episode : 96 / 10000 ; reward : 0.06 ; loss : 5.593014978550119\n","episode : 97 / 10000 ; reward : 0.1 ; loss : 5.750253823006945\n","episode : 98 / 10000 ; reward : 0.14857142857142858 ; loss : 5.981659593657218\n","episode : 99 / 10000 ; reward : 0.05142857142857143 ; loss : 6.402154260680002\n","episode : 100 / 10000 ; reward : 0.04 ; loss : 5.941886104678254\n","episode : 101 / 10000 ; reward : 0.025714285714285714 ; loss : 6.273581470918785\n","episode : 102 / 10000 ; reward : 0.04 ; loss : 5.878953025628811\n","episode : 103 / 10000 ; reward : 0.12857142857142856 ; loss : 6.024836808284352\n","episode : 104 / 10000 ; reward : 0.08571428571428572 ; loss : 6.22502702365699\n","episode : 105 / 10000 ; reward : 0.07428571428571429 ; loss : 6.779539508200245\n","episode : 106 / 10000 ; reward : 0.06857142857142857 ; loss : 6.551016316118645\n","episode : 107 / 10000 ; reward : 0.07142857142857142 ; loss : 6.765257956519727\n","episode : 108 / 10000 ; reward : 0.07142857142857142 ; loss : 5.693328755720791\n","episode : 109 / 10000 ; reward : 0.054285714285714284 ; loss : 6.462609296638545\n","episode : 110 / 10000 ; reward : 0.10285714285714286 ; loss : 5.801987701620076\n","episode : 111 / 10000 ; reward : 0.11142857142857143 ; loss : 6.442530973020761\n","episode : 112 / 10000 ; reward : 0.06285714285714286 ; loss : 6.236972836064327\n","episode : 113 / 10000 ; reward : 0.04285714285714286 ; loss : 5.967875846894657\n","episode : 114 / 10000 ; reward : 0.06857142857142857 ; loss : 5.83323303073738\n","episode : 115 / 10000 ; reward : 0.06571428571428571 ; loss : 6.3308242435131\n","episode : 116 / 10000 ; reward : 0.04 ; loss : 6.302172204894987\n","episode : 117 / 10000 ; reward : 0.04857142857142857 ; loss : 6.2337498879393864\n","episode : 118 / 10000 ; reward : 0.06 ; loss : 6.722569947019935\n","episode : 119 / 10000 ; reward : 0.13714285714285715 ; loss : 6.156574402511858\n","episode : 120 / 10000 ; reward : 0.03428571428571429 ; loss : 5.939178895019352\n","episode : 121 / 10000 ; reward : 0.07714285714285714 ; loss : 5.984972659515156\n","episode : 122 / 10000 ; reward : 0.09428571428571429 ; loss : 6.150661255684042\n","episode : 123 / 10000 ; reward : 0.17142857142857143 ; loss : 5.885151791916628\n","episode : 124 / 10000 ; reward : 0.05142857142857143 ; loss : 6.382500878703335\n","episode : 125 / 10000 ; reward : 0.08285714285714285 ; loss : 7.360164588769827\n","episode : 126 / 10000 ; reward : 0.06857142857142857 ; loss : 6.368184112274014\n","episode : 127 / 10000 ; reward : 0.04 ; loss : 7.3859060206691005\n","episode : 128 / 10000 ; reward : 0.03142857142857143 ; loss : 6.5910202778057645\n","episode : 129 / 10000 ; reward : 0.03142857142857143 ; loss : 5.899347066076716\n","episode : 130 / 10000 ; reward : 0.025714285714285714 ; loss : 6.905617376964413\n","episode : 131 / 10000 ; reward : 0.03428571428571429 ; loss : 7.119667210916502\n","episode : 132 / 10000 ; reward : 0.05714285714285714 ; loss : 6.256627313805405\n","episode : 133 / 10000 ; reward : 0.10857142857142857 ; loss : 6.342208307129578\n","episode : 134 / 10000 ; reward : 0.05714285714285714 ; loss : 5.750502649048306\n","episode : 135 / 10000 ; reward : 0.05714285714285714 ; loss : 5.587652878964966\n","episode : 136 / 10000 ; reward : 0.08571428571428572 ; loss : 7.214158600910333\n","episode : 137 / 10000 ; reward : 0.07142857142857142 ; loss : 6.385156170983155\n","episode : 138 / 10000 ; reward : 0.08571428571428572 ; loss : 6.8166117041659655\n","episode : 139 / 10000 ; reward : 0.037142857142857144 ; loss : 7.3083166516976155\n","episode : 140 / 10000 ; reward : 0.037142857142857144 ; loss : 6.32786511961889\n","episode : 141 / 10000 ; reward : 0.04285714285714286 ; loss : 6.645335352640089\n","episode : 142 / 10000 ; reward : 0.04857142857142857 ; loss : 6.776660414903661\n","episode : 143 / 10000 ; reward : 0.04285714285714286 ; loss : 6.330974308337805\n","episode : 144 / 10000 ; reward : 0.02857142857142857 ; loss : 6.505231885130322\n","episode : 145 / 10000 ; reward : 0.07142857142857142 ; loss : 6.545184395176207\n","episode : 146 / 10000 ; reward : 0.06857142857142857 ; loss : 6.633956558272861\n","episode : 147 / 10000 ; reward : 0.06 ; loss : 6.242448605762194\n","episode : 148 / 10000 ; reward : 0.06857142857142857 ; loss : 6.479624011998897\n","episode : 149 / 10000 ; reward : 0.054285714285714284 ; loss : 5.50469979954152\n","episode : 150 / 10000 ; reward : 0.08 ; loss : 5.667600360317022\n","episode : 151 / 10000 ; reward : 0.06 ; loss : 5.301800221525256\n","episode : 152 / 10000 ; reward : 0.05714285714285714 ; loss : 6.413899087044348\n","episode : 153 / 10000 ; reward : 0.08 ; loss : 6.387970004679918\n","episode : 154 / 10000 ; reward : 0.18 ; loss : 5.939175836339075\n","episode : 155 / 10000 ; reward : 0.15142857142857144 ; loss : 6.362376340135825\n","episode : 156 / 10000 ; reward : 0.14285714285714285 ; loss : 6.742622486252666\n","episode : 157 / 10000 ; reward : 0.045714285714285714 ; loss : 6.276581980826738\n","episode : 158 / 10000 ; reward : 0.037142857142857144 ; loss : 6.888508202289466\n","episode : 159 / 10000 ; reward : 0.04857142857142857 ; loss : 6.533877266631747\n","episode : 160 / 10000 ; reward : 0.04857142857142857 ; loss : 6.156640245440159\n","episode : 161 / 10000 ; reward : 0.06285714285714286 ; loss : 6.182030199173553\n","episode : 162 / 10000 ; reward : 0.02857142857142857 ; loss : 6.371218483226427\n","episode : 163 / 10000 ; reward : 0.054285714285714284 ; loss : 6.691119520934265\n","episode : 164 / 10000 ; reward : 0.04 ; loss : 6.453979974149338\n","episode : 165 / 10000 ; reward : 0.06285714285714286 ; loss : 6.614093723970252\n","episode : 166 / 10000 ; reward : 0.11428571428571428 ; loss : 5.8965866103899085\n","episode : 167 / 10000 ; reward : 0.09428571428571429 ; loss : 6.388385608366704\n","episode : 168 / 10000 ; reward : 0.022857142857142857 ; loss : 6.465413852074658\n","episode : 169 / 10000 ; reward : 0.09428571428571429 ; loss : 6.187904385779124\n","episode : 170 / 10000 ; reward : 0.08285714285714285 ; loss : 6.591113138840004\n","episode : 171 / 10000 ; reward : 0.06571428571428571 ; loss : 6.4796445009118155\n","episode : 172 / 10000 ; reward : 0.06 ; loss : 6.702697057609845\n","episode : 173 / 10000 ; reward : 0.07428571428571429 ; loss : 7.051330540482835\n","episode : 174 / 10000 ; reward : 0.02857142857142857 ; loss : 6.316755652199224\n","episode : 175 / 10000 ; reward : 0.1457142857142857 ; loss : 6.839785675239893\n","episode : 176 / 10000 ; reward : 0.05142857142857143 ; loss : 6.385415469004337\n","episode : 177 / 10000 ; reward : 0.13714285714285715 ; loss : 7.283070591673538\n","episode : 178 / 10000 ; reward : 0.05142857142857143 ; loss : 7.1774749940744105\n","episode : 179 / 10000 ; reward : 0.037142857142857144 ; loss : 6.308037309092279\n","episode : 180 / 10000 ; reward : 0.04285714285714286 ; loss : 6.393852430271875\n","episode : 181 / 10000 ; reward : 0.06571428571428571 ; loss : 6.696851641330131\n","episode : 182 / 10000 ; reward : 0.06571428571428571 ; loss : 6.914246370684263\n","episode : 183 / 10000 ; reward : 0.04285714285714286 ; loss : 6.348303444112314\n","episode : 184 / 10000 ; reward : 0.06857142857142857 ; loss : 7.428770627744086\n","episode : 185 / 10000 ; reward : 0.1657142857142857 ; loss : 6.248175552009721\n","episode : 186 / 10000 ; reward : 0.045714285714285714 ; loss : 6.7772881529387865\n","episode : 187 / 10000 ; reward : 0.03142857142857143 ; loss : 5.444954759872355\n","episode : 188 / 10000 ; reward : 0.04857142857142857 ; loss : 7.0743395889108\n","episode : 189 / 10000 ; reward : 0.04 ; loss : 6.742519898666149\n","episode : 190 / 10000 ; reward : 0.04 ; loss : 6.431063462649615\n","episode : 191 / 10000 ; reward : 0.03142857142857143 ; loss : 6.765913290307383\n","episode : 192 / 10000 ; reward : 0.05714285714285714 ; loss : 6.379797975850444\n","episode : 193 / 10000 ; reward : 0.037142857142857144 ; loss : 6.514306210959885\n","episode : 194 / 10000 ; reward : 0.06571428571428571 ; loss : 6.554144075682511\n","episode : 195 / 10000 ; reward : 0.08 ; loss : 5.816150711316352\n","episode : 196 / 10000 ; reward : 0.05714285714285714 ; loss : 6.4279142967423315\n","episode : 197 / 10000 ; reward : 0.04285714285714286 ; loss : 6.013641251865181\n","episode : 198 / 10000 ; reward : 0.05142857142857143 ; loss : 6.119526861098808\n","episode : 199 / 10000 ; reward : 0.05142857142857143 ; loss : 6.359600554818192\n","episode : 200 / 10000 ; reward : 0.09714285714285714 ; loss : 5.313608117230988\n","episode : 201 / 10000 ; reward : 0.06857142857142857 ; loss : 6.353957155549981\n","episode : 202 / 10000 ; reward : 0.022857142857142857 ; loss : 6.903044460026727\n","episode : 203 / 10000 ; reward : 0.09142857142857143 ; loss : 6.445368623881922\n","episode : 204 / 10000 ; reward : 0.12 ; loss : 6.242654964890445\n","episode : 205 / 10000 ; reward : 0.03142857142857143 ; loss : 6.382816145850431\n","episode : 206 / 10000 ; reward : 0.045714285714285714 ; loss : 5.902429397834212\n","episode : 207 / 10000 ; reward : 0.04285714285714286 ; loss : 6.068426598701847\n","episode : 208 / 10000 ; reward : 0.03142857142857143 ; loss : 6.3370067703695145\n","episode : 209 / 10000 ; reward : 0.06 ; loss : 5.170556393959523\n","episode : 210 / 10000 ; reward : 0.05142857142857143 ; loss : 6.279759159573745\n","episode : 211 / 10000 ; reward : 0.06 ; loss : 6.471264649771464\n","episode : 212 / 10000 ; reward : 0.03428571428571429 ; loss : 6.628482957413141\n","episode : 213 / 10000 ; reward : 0.11714285714285715 ; loss : 6.351209543639834\n","episode : 214 / 10000 ; reward : 0.05142857142857143 ; loss : 6.153839934894014\n","episode : 215 / 10000 ; reward : 0.06571428571428571 ; loss : 6.116670571818261\n","episode : 216 / 10000 ; reward : 0.03428571428571429 ; loss : 6.1595339167474386\n","episode : 217 / 10000 ; reward : 0.05714285714285714 ; loss : 6.419750063856268\n","episode : 218 / 10000 ; reward : 0.037142857142857144 ; loss : 6.34265867023216\n","episode : 219 / 10000 ; reward : 0.08571428571428572 ; loss : 6.608533121817912\n","episode : 220 / 10000 ; reward : 0.06571428571428571 ; loss : 6.716753738352015\n","episode : 221 / 10000 ; reward : 0.08 ; loss : 6.265186308022409\n","episode : 222 / 10000 ; reward : 0.05142857142857143 ; loss : 6.3110798551815375\n","episode : 223 / 10000 ; reward : 0.08571428571428572 ; loss : 6.908933738862987\n","episode : 224 / 10000 ; reward : 0.045714285714285714 ; loss : 7.057178743056297\n","episode : 225 / 10000 ; reward : 0.03142857142857143 ; loss : 6.2396465190289225\n","episode : 226 / 10000 ; reward : 0.054285714285714284 ; loss : 6.405513168248397\n","episode : 227 / 10000 ; reward : 0.037142857142857144 ; loss : 6.28244030578608\n","episode : 228 / 10000 ; reward : 0.03142857142857143 ; loss : 6.159328253784385\n","episode : 229 / 10000 ; reward : 0.054285714285714284 ; loss : 6.376853405678604\n","episode : 230 / 10000 ; reward : 0.03428571428571429 ; loss : 5.710667295634493\n","episode : 231 / 10000 ; reward : 0.16857142857142857 ; loss : 6.262536518471169\n","episode : 232 / 10000 ; reward : 0.09428571428571429 ; loss : 5.999471491813656\n","episode : 233 / 10000 ; reward : 0.07428571428571429 ; loss : 6.840288650444884\n","episode : 234 / 10000 ; reward : 0.045714285714285714 ; loss : 7.143354127564297\n","episode : 235 / 10000 ; reward : 0.04285714285714286 ; loss : 6.928925774059465\n","episode : 236 / 10000 ; reward : 0.04857142857142857 ; loss : 6.002540368192782\n","episode : 237 / 10000 ; reward : 0.08 ; loss : 6.825616275190119\n","episode : 238 / 10000 ; reward : 0.02857142857142857 ; loss : 6.805777621062246\n","episode : 239 / 10000 ; reward : 0.04857142857142857 ; loss : 6.325146256662955\n","episode : 240 / 10000 ; reward : 0.025714285714285714 ; loss : 7.283155930187921\n","episode : 241 / 10000 ; reward : 0.04 ; loss : 5.736659613298725\n","episode : 242 / 10000 ; reward : 0.1457142857142857 ; loss : 6.494030758022325\n","episode : 243 / 10000 ; reward : 0.09714285714285714 ; loss : 6.817339145098405\n","episode : 244 / 10000 ; reward : 0.10285714285714286 ; loss : 5.645537651809879\n","episode : 245 / 10000 ; reward : 0.08571428571428572 ; loss : 5.693646447401638\n","episode : 246 / 10000 ; reward : 0.045714285714285714 ; loss : 6.288499646428548\n","episode : 247 / 10000 ; reward : 0.09428571428571429 ; loss : 6.07673255589198\n","episode : 248 / 10000 ; reward : 0.08 ; loss : 6.725857140578802\n","episode : 249 / 10000 ; reward : 0.03142857142857143 ; loss : 6.3826062547519244\n","episode : 250 / 10000 ; reward : 0.03428571428571429 ; loss : 6.545750387635921\n","episode : 251 / 10000 ; reward : 0.03428571428571429 ; loss : 6.9945912736781795\n","episode : 252 / 10000 ; reward : 0.03428571428571429 ; loss : 6.385993949683372\n","episode : 253 / 10000 ; reward : 0.07714285714285714 ; loss : 6.728652665929764\n","episode : 254 / 10000 ; reward : 0.10285714285714286 ; loss : 6.294017913769437\n","episode : 255 / 10000 ; reward : 0.15428571428571428 ; loss : 6.13691615758056\n","episode : 256 / 10000 ; reward : 0.08285714285714285 ; loss : 6.128649409113964\n","episode : 257 / 10000 ; reward : 0.07142857142857142 ; loss : 6.6204354676296715\n","episode : 258 / 10000 ; reward : 0.07428571428571429 ; loss : 6.5803633838716635\n","episode : 259 / 10000 ; reward : 0.07428571428571429 ; loss : 6.659974299949965\n","episode : 260 / 10000 ; reward : 0.07714285714285714 ; loss : 6.257035704404981\n","episode : 261 / 10000 ; reward : 0.06 ; loss : 6.888828220340662\n","episode : 262 / 10000 ; reward : 0.06 ; loss : 6.640271932759263\n","episode : 263 / 10000 ; reward : 0.13714285714285715 ; loss : 6.253958008662166\n","episode : 264 / 10000 ; reward : 0.037142857142857144 ; loss : 5.9769886578873\n","episode : 265 / 10000 ; reward : 0.06857142857142857 ; loss : 6.5287248121955574\n","episode : 266 / 10000 ; reward : 0.08571428571428572 ; loss : 6.291745308711894\n","episode : 267 / 10000 ; reward : 0.06857142857142857 ; loss : 6.8004041194927645\n","episode : 268 / 10000 ; reward : 0.10857142857142857 ; loss : 6.903378524146101\n","episode : 269 / 10000 ; reward : 0.04857142857142857 ; loss : 6.70901109473257\n","episode : 270 / 10000 ; reward : 0.03142857142857143 ; loss : 7.049000280296956\n","episode : 271 / 10000 ; reward : 0.08571428571428572 ; loss : 6.1801061772508\n","episode : 272 / 10000 ; reward : 0.037142857142857144 ; loss : 6.892106412505803\n","episode : 273 / 10000 ; reward : 0.04857142857142857 ; loss : 6.154203042596291\n","episode : 274 / 10000 ; reward : 0.03428571428571429 ; loss : 6.3830717062422915\n","episode : 275 / 10000 ; reward : 0.045714285714285714 ; loss : 6.826218549353245\n","episode : 276 / 10000 ; reward : 0.15142857142857144 ; loss : 6.640454131147869\n","episode : 277 / 10000 ; reward : 0.06285714285714286 ; loss : 6.866107892123502\n","episode : 278 / 10000 ; reward : 0.04857142857142857 ; loss : 6.648955985500399\n","episode : 279 / 10000 ; reward : 0.05714285714285714 ; loss : 5.925557089072071\n","episode : 280 / 10000 ; reward : 0.12 ; loss : 6.348726201865325\n","episode : 281 / 10000 ; reward : 0.08857142857142856 ; loss : 6.13691979329735\n","episode : 282 / 10000 ; reward : 0.05714285714285714 ; loss : 6.966373825200707\n","episode : 283 / 10000 ; reward : 0.11428571428571428 ; loss : 6.634484593062044\n","episode : 284 / 10000 ; reward : 0.06857142857142857 ; loss : 7.829532654777535\n","episode : 285 / 10000 ; reward : 0.04285714285714286 ; loss : 5.962776873866884\n","episode : 286 / 10000 ; reward : 0.037142857142857144 ; loss : 6.763430467949817\n","episode : 287 / 10000 ; reward : 0.054285714285714284 ; loss : 6.222679420925878\n","episode : 288 / 10000 ; reward : 0.04285714285714286 ; loss : 7.368995527998567\n","episode : 289 / 10000 ; reward : 0.04857142857142857 ; loss : 6.442927183009917\n","episode : 290 / 10000 ; reward : 0.09714285714285714 ; loss : 6.282855386241676\n","episode : 291 / 10000 ; reward : 0.11142857142857143 ; loss : 6.411471883260871\n","episode : 292 / 10000 ; reward : 0.10571428571428572 ; loss : 6.2655853554265875\n","episode : 293 / 10000 ; reward : 0.11714285714285715 ; loss : 7.297872914440663\n","episode : 294 / 10000 ; reward : 0.06285714285714286 ; loss : 6.686055992041555\n","episode : 295 / 10000 ; reward : 0.02857142857142857 ; loss : 6.56293765163588\n","episode : 296 / 10000 ; reward : 0.06 ; loss : 6.331317260795893\n","episode : 297 / 10000 ; reward : 0.12285714285714286 ; loss : 6.368686265306766\n","episode : 298 / 10000 ; reward : 0.045714285714285714 ; loss : 7.026557496835006\n","episode : 299 / 10000 ; reward : 0.08857142857142856 ; loss : 6.983338085071724\n","episode : 300 / 10000 ; reward : 0.04857142857142857 ; loss : 6.46007560819652\n","episode : 301 / 10000 ; reward : 0.08 ; loss : 6.64863959916068\n","episode : 302 / 10000 ; reward : 0.1742857142857143 ; loss : 6.531817453660338\n"]}],"source":["Agent.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0RRopVRDGMav"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNgHQnFPuRtgdLlF4sOk848"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}